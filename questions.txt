
TODO:
Segmentation batch size = scene size --> not so easz vars on CPU etc...
Voxelization correct voxel size => check with scannet paper but ca 3cm?
feed propabilities per class directly into reconstruction
floor -> give larger weight
more scenes





////////////////////////////////////////
Meeting 10.7


Pointnet:
T-Net? not in sem_seg? augmenting enough? 
labels not from colors, instead use conversion from tsv file -> less labels
most papers ditch unknown label
centering pointcloud needed with blocks?
evaluating whole scene -> batch size? -> things left etc how to deal with different scene sizes
voxelization: radius? map to -1 1?
problem with floor?
stats....

Data:
preprocessing: how many sceens for the start? (batch size)

Reconstruction:
voxel size?























Email:


Problem: always same prediction -> class imbalance

Things done:
    "fake data" with just one label -> got that label as expected with 100% -> "no preprocessing/prediction bug"

Dataset:
    3 scenes 0001_00, 0002_00 and 0003_00 similar, however labeling quite strange? (cabinet vs. otherfurniture etc...)


Blocks removed -> really just becuase of memory?
"global context" that gets concatenated from block? -> audrey once said per scene, but this would mean I need to not build batches over scenes?




















////////////////////////////////////////
Meeting 20.6.2018

successfull able to train pointnet with Scannet scenes. 
Restoring the variabels for segmentation works in general, but one problem with variabels or so, bc always same label predicted
manual voxalize and feed into reconstruction worked too
Next steps: Solve prediction problem + combine all steps + refactor code

removed blocks, Batch now into currently 3000 points and feed into network
training accuracy/loss looks good but per class accuracy very low - many more classes than original paper
what about scale/roatation invariance

next steps after everything is combined? how to replace voxels by points, i.e. what should i try, where to start?


Other:
checked what martin meant by signing smth?
still no access to HIL building with my legi.























////////////////////////////////////////////////////////////
Meeting 1.6.2018


Dataset:
    Scannet: scene clean / 2 / 2.0 i.e. what use for training of segmentation network the clean ones?
        scan_clean2

    Feeding scannet into pointnet:
    color lables???? colored by nyu40 labels, but .ply property 'label' denotes the ScanNet label id -> convert? with what to work
    (used the ScanNet lable id as the color doesnt match the nyu40 from convert_scannet)

    PointNet currently uses 9 dim input namelz XYZ RGB and normalized location normalized location as to the room (from 0 to 1)
    -> how to handle for scannet? rooms etc?

    PointNet: train_data is Batch x Samples from block x 9 -> how to define block and then sample for scannet dataset

scannet training: feed in voxelgrid with each voxel just semantic info? no color etc? tsdf?


train_segmentation      -> train Pointnet
train_reconstruction    -> train LearningPriors: what to use? with output from pointnet

Evaluation:
First step:
    reconstruct.py -> feed pointcloud into segment.py -> get point segmentation -> convert to voxelgrid -> run reconstructtion
Second step:
    reconstruct.py -> feed pointcloud into segment.py -> get point segmentation -> do reconstruction from points???



shift to center: X - X_average



checked what martin meant by signing smth?

